1. seq2seq模型
	- Seq2Seq解决问题的主要思路是通过深度神经网络模型（常用的是LSTM，长短记忆网络，一种循环神经网络）。将一个作为输入的序列映射为一个作为输出的序列，这一过程由编码（Encoder）输入与解码（Decoder）输出两个环节组成, 前者负责把序列编码成一个固定长度的向量，这个向量作为输入传给后者，输出可变长度的向量。
	- 使用场景：在对话模型中，使用的语料是（（input）你说的话-我答的话（input））这种类型的pairs 。而在机器翻译中使用的语料是（hello-你好）这样的pairs。

2. 任务型对话机器人
	- modular/pipeline: 用户输入 -> NLU(自然语言理解) -> DST(对话状态跟踪) -> Action Generation(dialogue policy) -> NLG -> 输出
	- NLU: 文本 -> 意图(在一定的限制条件下)
	- DST: 解决的是多轮对话中的管理问题. 多轮对话中哪些信息需要记下, 哪些不需要.
	- DP: 生成对话策略. 根据DST得到的输出，决定产生什么动作.
	- NLG: 生成人类所用语言.

	